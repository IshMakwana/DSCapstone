{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and constants\n",
    "import time\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from sqlalchemy import MetaData, Table, Column, Integer, DateTime, Float\n",
    "from sqlalchemy import create_engine, select, insert, event\n",
    "from sqlalchemy.sql import text\n",
    "from sqlalchemy.engine import URL\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "normalizedColumns = {\n",
    "    'lpep_pickup_datetime': 'pickup_datetime', 'tpep_pickup_datetime': 'pickup_datetime',\n",
    "    'lpep_dropoff_datetime': 'dropoff_datetime', 'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "    'RatecodeID': 'ratecode_id',\n",
    "    'PULocationID': 'pu_location_id', \n",
    "    'DOLocationID': 'do_location_id',\n",
    "    'passenger_count': 'passenger_count', \n",
    "    'trip_distance': 'trip_distance', \n",
    "    'fare_amount': 'fare_amount', \n",
    "    'extra': 'extra', \n",
    "    'mta_tax': 'mta_tax',\n",
    "    'tip_amount': 'tip_amount', \n",
    "    'tolls_amount': 'tolls_amount', \n",
    "    'improvement_surcharge': 'improvement_surcharge',\n",
    "    'total_amount': 'total_amount', \n",
    "    'payment_type': 'payment_type', \n",
    "    'congestion_surcharge': 'congestion_surcharge'\n",
    "}\n",
    "\n",
    "# Functions\n",
    "def getODBCString():\n",
    "    SERVER = 'tcp:nyc-taxi-2024.database.windows.net,1433'\n",
    "    DATABASE = 'nyc_taxi_2024'\n",
    "    USERNAME = 'ishmakwana'\n",
    "    PASSWORD = 'xxx'\n",
    "\n",
    "    con_str = f'DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;'\n",
    "    return URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": con_str})\n",
    "\n",
    "def getSQLiteString():\n",
    "    return 'sqlite:///db/taxi_db.db'\n",
    "\n",
    "def getDateColumns(isGreen):\n",
    "    return ['lpep_pickup_datetime','lpep_dropoff_datetime'] if isGreen == True else ['tpep_pickup_datetime','tpep_dropoff_datetime']\n",
    "\n",
    "\n",
    "class TaxiDB:\n",
    "    def __init__(self, src, yr, isGreen = True):\n",
    "        self.md = MetaData()\n",
    "        self.yr = yr\n",
    "        self.g = isGreen\n",
    "        self.src = src\n",
    "\n",
    "        # self.engn = create_engine(getODBCString())\n",
    "        self.engn = create_engine(getSQLiteString())\n",
    "        self.md.reflect(self.engn)\n",
    "        print('sql engine ready')\n",
    "\n",
    "        with self.engn.connect() as conn:\n",
    "            conn.rollback()\n",
    "\n",
    "        # @event.listens_for(self.engn, 'before_cursor_execute')\n",
    "        # def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "        #     # print(f'params: {params}')\n",
    "        #     if executemany:\n",
    "        #         cursor.fast_executemany = True\n",
    "\n",
    "        # self.createTable()\n",
    "        # print(f'table created: {self.getTableName()}')\n",
    "        \n",
    "        self.table = self.md.tables[self.getTableName()]\n",
    "\n",
    "    def describeTables(self):\n",
    "        with self.engn.connect() as conn:\n",
    "            for t in self.md.tables.keys():\n",
    "                result = conn.execute(text(f'select COUNT(1) from {self.md.tables[t]}'))\n",
    "                print(f'table name: {t}, #rows: {result.scalar()}')\n",
    "    \n",
    "    def printRowCount(self):\n",
    "        with self.engn.connect() as conn:\n",
    "            result = conn.execute(text(f'select COUNT(1) from {self.getTableName()}'))\n",
    "            print(result.scalar())\n",
    "\n",
    "    def prepareData(self):\n",
    "        fc = []\n",
    "        for c in self.df.columns:\n",
    "            if c in normalizedColumns.keys():\n",
    "                fc.append(normalizedColumns[c])\n",
    "        self.df.rename(columns=normalizedColumns, inplace=True)\n",
    "        self.df = self.df[fc]\n",
    "\n",
    "        self.df.fillna(0, inplace=True)\n",
    "        for ic in ['ratecode_id','pu_location_id','do_location_id','passenger_count','payment_type']:\n",
    "            self.df[ic] = self.df[ic].astype(int)\n",
    "\n",
    "        print(f'columns: {list(self.df.columns)}, #rows: {len(self.df)}')\n",
    "        \n",
    "    def getTableName(self):\n",
    "        colr = 'green' if self.g == True else 'yellow'\n",
    "        return f'{colr}_taxi_trips{self.yr}'\n",
    "\n",
    "    def createTable(self):\n",
    "        Table(\n",
    "            self.getTableName(), self.md, \n",
    "            Column('id', Integer, primary_key = True), \n",
    "            Column('pickup_datetime', DateTime), \n",
    "            Column('dropoff_datetime', DateTime), \n",
    "            Column('ratecode_id', Integer), \n",
    "            Column('pu_location_id', Integer), \n",
    "            Column('do_location_id', Integer), \n",
    "            Column('passenger_count', Integer), \n",
    "            Column('trip_distance', Float), \n",
    "            Column('fare_amount', Float), \n",
    "            Column('extra', Float), \n",
    "            Column('mta_tax', Float), \n",
    "            Column('tip_amount', Float), \n",
    "            Column('tolls_amount', Float), \n",
    "            Column('improvement_surcharge', Float), \n",
    "            Column('total_amount', Float), \n",
    "            Column('payment_type', Integer), \n",
    "            Column('congestion_surcharge', Float),\n",
    "            # extend_existing=True,\n",
    "            keep_existing=True\n",
    "        )\n",
    "\n",
    "        self.md.create_all(self.engn)\n",
    "\n",
    "    def dropTableByName(self, name):\n",
    "        if name in self.md.tables.keys():\n",
    "            self.dropTable(self.md.tables[name])\n",
    "\n",
    "    def dropTable(self, table):\n",
    "        with self.engn.connect() as conn:\n",
    "            # result = conn.execute(table.select())\n",
    "            # result.fetchall()\n",
    "            # conn.close()\n",
    "\n",
    "            try:\n",
    "                table.drop(self.engn)\n",
    "                conn.commit()\n",
    "                print('table dropped')\n",
    "            except Exception as e:\n",
    "                print(f'could not drop table: {traceback.format_exc()}')\n",
    "                conn.rollback()\n",
    "    \n",
    "    def uploadTable(self, chunksize = 2000000):\n",
    "        s = time.time()\n",
    "\n",
    "        inserted = 0\n",
    "        with pd.read_csv(self.src, \n",
    "                         chunksize=chunksize, \n",
    "                         parse_dates=getDateColumns(self.g),\n",
    "                         date_format=\"%m/%d/%Y %I:%M:%S %p\") as reader:\n",
    "            for df in reader:\n",
    "                self.df = df\n",
    "                self.prepareData()\n",
    "                inserted += len(self.df)\n",
    "                \n",
    "                # if inserted <= 28000000:\n",
    "                #     print(f'{inserted} records skipped')\n",
    "                #     continue\n",
    "                \n",
    "                with self.engn.connect() as conn:\n",
    "                    records = self.df.to_dict('records')\n",
    "                    print(f'{inserted} records processed')\n",
    "                    try:\n",
    "                        conn.execute(insert(self.table), records)\n",
    "                        conn.commit()\n",
    "                        print('committed')\n",
    "                    except Exception as e:\n",
    "                        print(f'commit failed: {traceback.format_exc()}')\n",
    "                        conn.rollback()\n",
    "                        print('rolled back')\n",
    "        \n",
    "        print(f'upload complete, time taken: {time.time() - s} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql engine ready\n",
      "table name: green_taxi_trips2020, #rows: 1675896\n",
      "table name: green_taxi_trips2021, #rows: 1011529\n",
      "table name: green_taxi_trips2022, #rows: 808818\n",
      "table name: green_taxi_trips2023, #rows: 761980\n",
      "table name: taxi_zones, #rows: 263\n",
      "table name: yellow_taxi_trips2020, #rows: 24014901\n",
      "table name: yellow_taxi_trips2021, #rows: 29905605\n",
      "table name: yellow_taxi_trips2022, #rows: 38133567\n",
      "table name: yellow_taxi_trips2023, #rows: 36565008\n"
     ]
    }
   ],
   "source": [
    "# Playground 1\n",
    "\n",
    "sources = [\n",
    "            ('data/2023_Yellow_Taxi_Trip_Data.csv', 2023, False),\n",
    "            ('data/2023_Green_Taxi_Trip_Data.csv', 2023, True),\n",
    "            ('data/2022_Yellow_Taxi_Trip_Data.csv', 2022, False),\n",
    "            ('data/2022_Green_Taxi_Trip_Data.csv', 2022, True),\n",
    "            ('data/2021_Yellow_Taxi_Trip_Data.csv', 2021, False),\n",
    "            ('data/2021_Green_Taxi_Trip_Data.csv', 2021, True),\n",
    "            ('data/2020_Yellow_Taxi_Trip_Data.csv', 2020, False),\n",
    "            ('data/2020_Green_Taxi_Trip_Data.csv', 2020, True)\n",
    "            ]\n",
    "\n",
    "# Setting the year and whether we're uploading green or yellow.\n",
    "# This is needed because each csv goes into it's own table, \n",
    "#   and setting params like this will make accessing data from tables easier. \n",
    "\n",
    "# Connect to the SQL Database\n",
    "for item in sources:\n",
    "    src, year, green = item\n",
    "    mydb = TaxiDB(src, year, green)\n",
    "    # mydb.printRowCount()\n",
    "\n",
    "    # Read from csv and insert into SQL table. \n",
    "    # Commented as data already uploaded, and we don't want to duplicate our data ;)\n",
    "    # mydb.uploadTable()\n",
    "\n",
    "    # Prints all the talbes in the DB, and # of rows in each table. \n",
    "    mydb.describeTables()\n",
    "    break\n",
    "\n",
    "    # Drops current table. \n",
    "    # Commented as we don't actually want to drop, and reuploading will cost time :(\n",
    "    # mydb.dropTable(mydb.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(getSQLiteString())\n",
    "md = MetaData()\n",
    "md.reflect(engine)\n",
    "    \n",
    "with engine.connect() as conn:\n",
    "    sql = text('SELECT * FROM taxi_zones')\n",
    "    df = pd.read_sql(sql, conn)\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   zone_length    263 non-null    float64\n",
      " 1   zone_shape     263 non-null    object \n",
      " 2   zone_area      263 non-null    float64\n",
      " 3   zone           263 non-null    object \n",
      " 4   location_id    263 non-null    int64  \n",
      " 5   location_name  263 non-null    object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 12.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# create taxi zone table\n",
    "source = 'data/taxi_zones.csv'\n",
    "\n",
    "df = pd.read_csv(source)\n",
    "\n",
    "og_zone_columns = ['Shape_Leng', 'the_geom', 'Shape_Area' , 'zone', 'LocationID', 'borough']\n",
    "zone_column_map = {\n",
    "    'Shape_Leng': 'zone_length', \n",
    "    'the_geom': 'zone_shape', \n",
    "    'Shape_Area': 'zone_area' , \n",
    "    'zone': 'zone', \n",
    "    'LocationID': 'location_id', \n",
    "    'borough': 'location_name'\n",
    "    }\n",
    "\n",
    "df = df[og_zone_columns]\n",
    "df = df.rename(columns=zone_column_map)\n",
    "df.info()\n",
    "\n",
    "engine = create_engine(getSQLiteString())\n",
    "md = MetaData()\n",
    "md.reflect(engine)\n",
    "    \n",
    "with engine.connect() as conn:\n",
    "    df.to_sql('taxi_zones', conn, if_exists='replace')\n",
    "    conn.commit()\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
